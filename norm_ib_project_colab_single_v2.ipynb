{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Retmmmy/finding-vulnerabilities/blob/main/norm_ib_project_colab_single_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkOe7EXJXIot"
      },
      "source": [
        "# IB Project\n"
      ],
      "id": "jkOe7EXJXIot"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK6E6lblXIoz"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "!pip -q uninstall -y transformers tokenizers accelerate datasets evaluate safetensors || true\n",
        "!pip -q install -U \"transformers\" \"datasets\" \"accelerate\" \"evaluate\" \"safetensors\"\n"
      ],
      "id": "ZK6E6lblXIoz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_u0mVXHXIo5"
      },
      "source": [
        "## 1) Импорты и настройки\n"
      ],
      "id": "A_u0mVXHXIo5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVaQWEoXIo8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, random, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n"
      ],
      "id": "OgVaQWEoXIo8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_DGRzytXIo-"
      },
      "source": [
        "## 2) Загрузка датасета и единый split\n",
        "\n",
        "Используем `DynaOuchebara/BigVul` (поле кода: `func_before`, метка: `vul`).\n"
      ],
      "id": "B_DGRzytXIo-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I16qYcM9XIo_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "MAX_TRAIN = 20000\n",
        "MAX_VAL   = 2000\n",
        "MAX_TEST  = 2000\n",
        "\n",
        "ds = load_dataset(\"DynaOuchebara/BigVul\")\n",
        "\n",
        "\n",
        "train_ds = ds[\"train\"]\n",
        "\n",
        "texts = train_ds[\"func_before\"]\n",
        "labels = train_ds[\"vul\"]\n",
        "\n",
        "clean = [(t, int(y)) for t, y in zip(texts, labels) if isinstance(t, str) and t.strip() != \"\"]\n",
        "texts = [t for t,_ in clean]\n",
        "labels = [y for _,y in clean]\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "def maybe_trunc(X, y, max_n):\n",
        "    if max_n is None:\n",
        "        return X, y\n",
        "    X = X[:max_n]\n",
        "    y = y[:max_n]\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = maybe_trunc(X_train, y_train, MAX_TRAIN)\n",
        "X_val,   y_val   = maybe_trunc(X_val,   y_val,   MAX_VAL)\n",
        "X_test,  y_test  = maybe_trunc(X_test,  y_test,  MAX_TEST)\n",
        "\n",
        "print(\"Sizes:\", len(X_train), len(X_val), len(X_test))\n",
        "print(\"Pos rate test:\", np.mean(y_test))\n"
      ],
      "id": "I16qYcM9XIo_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjnsN3E2XIpG"
      },
      "source": [
        "## 3) Утилиты метрик\n"
      ],
      "id": "EjnsN3E2XIpG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY5k76PIXIpH"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_metrics_from_logits(logits: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
        "\n",
        "    if logits.ndim == 2 and logits.shape[1] == 2:\n",
        "        probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "        y_pred = (probs >= 0.5).astype(int)\n",
        "    else:\n",
        "        probs = 1/(1+np.exp(-logits))\n",
        "        y_pred = (probs >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"precision\": float(prec),\n",
        "        \"recall\": float(rec),\n",
        "        \"f1\": float(f1),\n",
        "        \"roc_auc\": float(auc),\n",
        "    }\n"
      ],
      "id": "jY5k76PIXIpH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIDUjOYXIpJ"
      },
      "source": [
        "## 4) Baselines на PyTorch\n",
        "\n",
        "### 4.1 Простая byte-level токенизация\n",
        "baselines делается на PyTorch, код токенизируется как последовательность байт\n"
      ],
      "id": "8wIDUjOYXIpJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcFbYOP5XIpL"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ByteTokenizerConfig:\n",
        "    max_len: int = 512\n",
        "\n",
        "class ByteTokenizer:\n",
        "    def __init__(self, cfg: ByteTokenizerConfig):\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "\n",
        "        b = text.encode(\"utf-8\", errors=\"ignore\")[: self.cfg.max_len]\n",
        "        ids = [x + 1 for x in b]\n",
        "        if len(ids) < self.cfg.max_len:\n",
        "            ids = ids + [0] * (self.cfg.max_len - len(ids))\n",
        "        return ids\n",
        "\n",
        "byte_tok = ByteTokenizer(ByteTokenizerConfig(max_len=512))\n"
      ],
      "id": "vcFbYOP5XIpL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml-VsNjuXIpM"
      },
      "source": [
        "### 4.2 Dataset/Dataloader\n"
      ],
      "id": "ml-VsNjuXIpM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVV5HKcMXIpN"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TextClsDataset(Dataset):\n",
        "    def __init__(self, X: List[str], y: List[int], tokenizer: ByteTokenizer):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        ids = torch.tensor(self.tokenizer.encode(self.X[idx]), dtype=torch.long)\n",
        "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return {\"input_ids\": ids, \"labels\": label}\n",
        "\n",
        "def make_loader(X, y, bs=32, shuffle=False):\n",
        "    ds = TextClsDataset(X, y, byte_tok)\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=2, pin_memory=True)\n",
        "\n",
        "train_loader = make_loader(X_train, y_train, bs=32, shuffle=True)\n",
        "val_loader   = make_loader(X_val,   y_val,   bs=64, shuffle=False)\n",
        "test_loader  = make_loader(X_test,  y_test,  bs=64, shuffle=False)\n"
      ],
      "id": "CVV5HKcMXIpN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2OIGyWtXIpO"
      },
      "source": [
        "### 4.3 Модели: MLP / CNN / GRU / LSTM\n"
      ],
      "id": "Z2OIGyWtXIpO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbJl0NvZXIpQ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "class BaseByteModel(nn.Module):\n",
        "    def __init__(self, vocab_size=257, emb_dim=128, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "class MLPByte(BaseByteModel):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.emb(input_ids)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        return self.net(x)\n",
        "\n",
        "class CNNByte(BaseByteModel):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "        )\n",
        "        self.fc = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.emb(input_ids).transpose(1,2)\n",
        "        x = self.conv(x).squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class GRUByte(BaseByteModel):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.rnn = nn.GRU(input_size=128, hidden_size=128, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.emb(input_ids)\n",
        "        out, h = self.rnn(x)\n",
        "        h = torch.cat([h[0], h[1]], dim=1)\n",
        "        return self.fc(h)\n",
        "\n",
        "class LSTMByte(BaseByteModel):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.rnn = nn.LSTM(input_size=128, hidden_size=128, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.emb(input_ids)\n",
        "        out, (h, c) = self.rnn(x)\n",
        "        h = torch.cat([h[0], h[1]], dim=1)\n",
        "        return self.fc(h)\n"
      ],
      "id": "MbJl0NvZXIpQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUYsHYH1XIpR"
      },
      "source": [
        "### 4.4 Train/Eval loop для baselines\n"
      ],
      "id": "NUYsHYH1XIpR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGQBJwgXXIpS"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_one_model(model: nn.Module, name: str, epochs: int = 2, lr: float = 2e-4):\n",
        "    model = model.to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_state = None\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for batch in train_loader:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            y = batch[\"labels\"].to(DEVICE)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(ids)\n",
        "            loss = loss_fn(logits, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += float(loss.item())\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        all_logits, all_y = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                ids = batch[\"input_ids\"].to(DEVICE)\n",
        "                y = batch[\"labels\"].cpu().numpy()\n",
        "                logits = model(ids).cpu().numpy()\n",
        "                all_logits.append(logits)\n",
        "                all_y.append(y)\n",
        "        all_logits = np.concatenate(all_logits, axis=0)\n",
        "        all_y = np.concatenate(all_y, axis=0)\n",
        "        m = compute_metrics_from_logits(all_logits, all_y)\n",
        "\n",
        "        print(f\"[{name}] epoch {ep} train_loss={total/len(train_loader):.4f} val_f1={m['f1']:.4f}\")\n",
        "\n",
        "        if m[\"f1\"] > best_val_f1:\n",
        "            best_val_f1 = m[\"f1\"]\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    all_logits, all_y = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            y = batch[\"labels\"].cpu().numpy()\n",
        "            logits = model(ids).cpu().numpy()\n",
        "            all_logits.append(logits)\n",
        "            all_y.append(y)\n",
        "    all_logits = np.concatenate(all_logits, axis=0)\n",
        "    all_y = np.concatenate(all_y, axis=0)\n",
        "    test_metrics = compute_metrics_from_logits(all_logits, all_y)\n",
        "    return test_metrics\n",
        "\n",
        "baseline_results = {}\n",
        "baseline_results[\"MLP\"]  = train_one_model(MLPByte(), \"MLP\", epochs=2)\n",
        "baseline_results[\"CNN\"]  = train_one_model(CNNByte(), \"CNN\", epochs=2)\n",
        "baseline_results[\"GRU\"]  = train_one_model(GRUByte(), \"GRU\", epochs=2)\n",
        "baseline_results[\"LSTM\"] = train_one_model(LSTMByte(), \"LSTM\", epochs=2)\n",
        "\n",
        "baseline_results\n"
      ],
      "id": "bGQBJwgXXIpS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmCxc9YZXIpV"
      },
      "source": [
        "## 5) CodeBERT (Transformers)\n"
      ],
      "id": "RmCxc9YZXIpV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHebDDh7XIpY"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import inspect\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"microsoft/codebert-base\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_batch(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "from datasets import Dataset as HFDataset\n",
        "\n",
        "hf_train = HFDataset.from_dict({\"text\": X_train, \"label\": y_train}).map(tokenize_batch, batched=True)\n",
        "hf_val   = HFDataset.from_dict({\"text\": X_val,   \"label\": y_val}).map(tokenize_batch, batched=True)\n",
        "hf_test  = HFDataset.from_dict({\"text\": X_test,  \"label\": y_test}).map(tokenize_batch, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def hf_compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc}\n",
        "\n",
        "\n",
        "out_dir = \"artifacts/codebert_model\"\n",
        "ta_params = set(inspect.signature(TrainingArguments.__init__).parameters.keys())\n",
        "eval_key = \"evaluation_strategy\" if \"evaluation_strategy\" in ta_params else \"eval_strategy\"\n",
        "\n",
        "ta_kwargs = dict(\n",
        "    output_dir=out_dir,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "ta_kwargs[eval_key] = \"epoch\"\n",
        "ta_kwargs[\"save_strategy\"] = \"epoch\"\n",
        "\n",
        "args = TrainingArguments(**ta_kwargs)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=hf_train,\n",
        "    eval_dataset=hf_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=hf_compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "codebert_test = trainer.evaluate(hf_test)\n",
        "codebert_test\n"
      ],
      "id": "RHebDDh7XIpY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu6xNf-4XIpZ"
      },
      "source": [
        "## 6) Сводная таблица метрик и сохранение (CSV/JSON)\n"
      ],
      "id": "xu6xNf-4XIpZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwmiNYGtXIpZ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "\n",
        "\n",
        "rows = []\n",
        "for k, v in baseline_results.items():\n",
        "    rows.append({\"model\": k, **v})\n",
        "rows.append({\"model\": \"CodeBERT\", **{k: float(v) for k, v in codebert_test.items() if k in [\"eval_accuracy\",\"eval_precision\",\"eval_recall\",\"eval_f1\",\"eval_roc_auc\"]}})\n",
        "\n",
        "\n",
        "fixed_rows = []\n",
        "for r in rows:\n",
        "    rr = dict(r)\n",
        "    if rr[\"model\"] == \"CodeBERT\":\n",
        "        rr[\"accuracy\"]  = rr.pop(\"eval_accuracy\")\n",
        "        rr[\"precision\"] = rr.pop(\"eval_precision\")\n",
        "        rr[\"recall\"]    = rr.pop(\"eval_recall\")\n",
        "        rr[\"f1\"]        = rr.pop(\"eval_f1\")\n",
        "        rr[\"roc_auc\"]   = rr.pop(\"eval_roc_auc\")\n",
        "    fixed_rows.append(rr)\n",
        "\n",
        "df = pd.DataFrame(fixed_rows)[[\"model\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"]]\n",
        "df.to_csv(\"artifacts/metrics_comparison.csv\", index=False)\n",
        "with open(\"artifacts/metrics_comparison.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(fixed_rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "df\n"
      ],
      "id": "kwmiNYGtXIpZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuAeQYo7XIpa"
      },
      "source": [
        "## 7)Gradio-инференс для CodeBERT\n"
      ],
      "id": "NuAeQYo7XIpa"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio\n"
      ],
      "metadata": {
        "id": "ZI4CJmQK_5_Z"
      },
      "id": "ZI4CJmQK_5_Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "49191_xK__zZ"
      },
      "id": "49191_xK__zZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4G1x643XIpa"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def predict(text: str):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=True\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = torch.softmax(logits, dim=1)[0]\n",
        "\n",
        "    return {\n",
        "        \"non_vuln\": round(float(probs[0]), 4),\n",
        "        \"vuln\": round(float(probs[1]), 4),\n",
        "        \"decision\": \"VULNERABLE\" if probs[1] > 0.5 else \"SAFE\"\n",
        "    }\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=12, label=\"C/C++ code\"),\n",
        "    outputs=gr.JSON(),\n",
        "    title=\"CodeBERT Vuln Classifier\"\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "id": "w4G1x643XIpa"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import gradio as gr\n",
        "except Exception:\n",
        "    !pip -q install gradio\n",
        "    import gradio as gr\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "vuln_idx = [i for i, y in enumerate(y_test) if int(y) == 1]\n",
        "safe_idx = [i for i, y in enumerate(y_test) if int(y) == 0]\n",
        "random.shuffle(vuln_idx)\n",
        "random.shuffle(safe_idx)\n",
        "\n",
        "def _predict_one(text: str):\n",
        "    model.to(DEVICE).eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = torch.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
        "    pred = int(np.argmax(probs))\n",
        "    return {\n",
        "        \"non-vuln\": float(probs[0]),\n",
        "        \"vuln\": float(probs[1]),\n",
        "        \"__pred_label__\": pred,\n",
        "    }\n",
        "\n",
        "def _format_truth(i: int):\n",
        "    y = int(y_test[i])\n",
        "    return f\"**Ground truth:** `{y}` ({'vuln' if y==1 else 'non-vuln'})  \\n**Index:** `{i}`\"\n",
        "\n",
        "def next_example(kind: str, ptr_v: int, ptr_s: int):\n",
        "    if kind == \"vuln\":\n",
        "        i = vuln_idx[ptr_v % len(vuln_idx)]\n",
        "        ptr_v += 1\n",
        "    else:\n",
        "        i = safe_idx[ptr_s % len(safe_idx)]\n",
        "        ptr_s += 1\n",
        "\n",
        "    text = X_test[i]\n",
        "    truth_md = _format_truth(i)\n",
        "    return text, truth_md, ptr_v, ptr_s\n",
        "\n",
        "def random_example():\n",
        "    i = random.randrange(len(X_test))\n",
        "    return X_test[i], _format_truth(i)\n",
        "\n",
        "def predict_current(text: str):\n",
        "    out = _predict_one(text)\n",
        "    pred = out[\"__pred_label__\"]\n",
        "\n",
        "    label_dict = {\"non-vuln\": out[\"non-vuln\"], \"vuln\": out[\"vuln\"]}\n",
        "    pred_md = f\"**Prediction:** `{pred}` ({'vuln' if pred==1 else 'non-vuln'})\"\n",
        "    return label_dict, pred_md\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# CodeBERT Vuln Classifier —\"\n",
        "                \"Кнопки **Next vuln / Next non-vuln** подставляют реальные примеры из `X_test`.\\n\"\n",
        "                \"Нажми **Predict** чтобы увидеть вероятности и предсказание.\\n\")\n",
        "\n",
        "    ptr_v = gr.State(0)\n",
        "    ptr_s = gr.State(0)\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_v = gr.Button(\"Next vuln (y=1)\")\n",
        "        btn_s = gr.Button(\"Next non-vuln (y=0)\")\n",
        "        btn_r = gr.Button(\"Random example\")\n",
        "\n",
        "    text = gr.Textbox(lines=14, label=\"C/C++ code (from test set or your own)\")\n",
        "    truth = gr.Markdown(\"**Ground truth:** (press Next/Random)\")\n",
        "    with gr.Row():\n",
        "        btn_p = gr.Button(\"Predict\")\n",
        "        out_label = gr.Label(label=\"Probabilities\")\n",
        "    pred_md = gr.Markdown(\"**Prediction:** (press Predict)\")\n",
        "\n",
        "    btn_v.click(fn=lambda pv, ps: next_example(\"vuln\", pv, ps),\n",
        "                inputs=[ptr_v, ptr_s],\n",
        "                outputs=[text, truth, ptr_v, ptr_s])\n",
        "\n",
        "    btn_s.click(fn=lambda pv, ps: next_example(\"safe\", pv, ps),\n",
        "                inputs=[ptr_v, ptr_s],\n",
        "                outputs=[text, truth, ptr_v, ptr_s])\n",
        "\n",
        "    btn_r.click(fn=random_example, inputs=[], outputs=[text, truth])\n",
        "\n",
        "    btn_p.click(fn=predict_current, inputs=[text], outputs=[out_label, pred_md])\n",
        "\n",
        "demo.launch(debug=False)\n"
      ],
      "metadata": {
        "id": "13one1-BhsRv"
      },
      "id": "13one1-BhsRv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "pred_out = trainer.predict(hf_test)\n",
        "logits = pred_out.predictions\n",
        "labels = pred_out.label_ids\n",
        "\n",
        "probs_vuln = np.exp(logits[:,1]) / (np.exp(logits[:,0]) + np.exp(logits[:,1]))\n",
        "preds = (probs_vuln >= 0.5).astype(int)\n",
        "\n",
        "tp = int(((preds == 1) & (labels == 1)).sum())\n",
        "fn = int(((preds == 0) & (labels == 1)).sum())\n",
        "\n",
        "recall_vuln = tp / (tp + fn) if (tp + fn) > 0 else float(\"nan\")\n",
        "\n",
        "print(\"TP:\", tp, \"FN:\", fn)\n",
        "print(f\"Recall(vuln) = {recall_vuln:.4f}  ({recall_vuln*100:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "k9S3_i7gkQz2"
      },
      "id": "k9S3_i7gkQz2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}